\chapter{METHODOLGIES \& IMPLEMENTATION}

This section of the thesis aims to provide a clear understanding of how the re-implementation was conducted in C. Providing all the steps taken in this attempt, with as much technical detail as possible and referencing appropriate sections of the original paper.

\subsection{Data structures, and Initial Parse Trees}
\subsubsection{Data Structures}
During this process of re-implementation, 2 structures were initialised. Structures are a way to group several related variables into one place in C \cite{w3schoolStructuresStructs2025}. One structure to represent a node in the parse trees, and another structure to hold and reference each parse tree.
\begin{figure}[H]

    \begin{tcolorbox}[title=Nodes Structure for storing trees, colback=white, colframe=black]
        \begin{lstlisting}[
            language=C,
            numbers=left,
            stepnumber=1,
            numbersep=5pt,
            xleftmargin=1.5em,
            frame=none
        ]
        typedef struct nodes{
            int capacity;
            int count;
            struct node **rootNodes;
        } Nodes;
        \end{lstlisting}

    \end{tcolorbox}

\caption{Data Structure to store and track trees}
\label{fig:Data_Structures1}
\end{figure}

Figure \ref{fig:Data_Structures1} shows the structure $Nodes$, used to hold all the parse trees. It has variables called \texttt{rootNodes}, which is a list containing pointers to the roots of all the parse trees. Now, as this implementation is in C and memory management is a dynamic and manual process, this structure holds 2 more variables \texttt{capacity} and \texttt{count}. Both of these variables are integers that are used to help manage the size of \texttt{rootNodes}. Variable \texttt{capacity} tracks the number of root node pointers \texttt{rootNodes} can currently hold, and variable $count$ tracks the number of actual root node pointers $rootNode$ currently has.

\begin{figure}[H]

    \begin{tcolorbox}[title=Node Structure to build each tree, colback=white, colframe=black]

        \begin{lstlisting}[
            language=C,
            numbers=left,
            stepnumber=1,
            numbersep=5pt,
            xleftmargin=1.5em,
            frame=none
        ]
        typedef struct node{
            int capacity;
            char character;
            struct node *parent;
            int t_label;
            int num_child;
            int pos;
            struct node **children;
        } Node;
        \end{lstlisting}
    \end{tcolorbox}

\caption{Data Structure to build each tree}
\label{fig:Data_Structures2}
\end{figure}


Figure \ref{fig:Data_Structures2} shows the structure $Node$, used for each individual node in the trees. It has 7 variables inside it. 
\begin{itemize}
    \item \texttt{character}: stores a C character if the node is a leaf/terminal node, else a null character if the node is a non-terminal.
    \item  \texttt{t\_label}: stores an integer. The integer is a positive value if the node is a non-terminal, else -1 if it is a terminal.
    \item \texttt{parent}: hold a pointer to the current node's parent, which is a $Node$ as well. If root, parent is a null pointer.
    \item \texttt{pos}: is an integer which represents the index of the current node when the parse trees are initially constructed for all terminal nodes. For non-terminal nodes, it will be a null value.
    \item \texttt{children}: hold a list of pointer, which point to $Node$.
    \item \texttt{capacity}: current size of the list $children$. 
    \item \texttt{num\_child}: current number of $Node$(s) pointer in list \texttt{children}.
\end{itemize}

\subsubsection{Building Initial parse trees}
This part of the thesis is derived from section III-A of the original paper \cite{kulkarniLearningHighlyRecursive2021}. Using the 2 structures described, next, the initial parse trees were built. First, we build the $Nodes$ structure, which houses all the parse tree pointers. 
This is done by using C's built-in dynamic memory function $malloc$, where $capacity$ was set randomly to 4, $count$ to 0, as it does not house any parse tree pointers yet, and list $rootNodes$ was given enough memory to house 4 $Node$ pointers, where 4 is the current $capacity$. 

\begin{figure}[H]
    \begin{lstlisting}[
        language=C,
        numbers=left,
        stepnumber=1,
        numbersep=5pt,
        xleftmargin=1.5em,
        frame=none
    ]
    // Keeping track of all root trees (each string in example file)
    Nodes *root_trees= malloc(sizeof(Nodes)); 
    root_trees->capacity = 4; // randomly assigned
    root_trees->count = 0;
    root_trees->rootNodes= malloc(root_trees->capacity * sizeof(Node*));

    \end{lstlisting}

\caption{building of Nodes Structure}
\label{fig:rootNodes}
\end{figure}

Next, the file containing all the valid example strings is read as standard. Refer to figure \ref{fig:buildeachParseTree}, then from the top of the file, each valid string is read and each naive flat parse tree is built one by one. After each tree is built, the pointer to the tree's root if given and housed in \texttt{root\_trees} from figure \ref{fig:rootNodes}. 


\subsubsection{Memory management}

As the number of valid example strings and the length of each example string are not pre-determined, the number of \texttt{Nodes} (each parse tree), and the number of leaf nodes each non-terminal root node is going to is also non-determined. This means memory has to be allocated dynamically. To do this, two functions are used: one function to check and increase memory allocated to \texttt{root\_nodes} in \texttt{Nodes}, and another to check and increase memory allocated to \texttt{children} in \texttt{Node}. Both these functions check the \texttt{capacity} of their respective structures, and if \texttt{count} for \texttt{Nodes} and \texttt{num\_child} for \texttt{Node} equals \texttt{capacity}, they increase the memory allocated to their respective lists by 1.5 times the \texttt{capacity}, updating other variables appropriately. Function code in the appendix \ref{fig:capacityChangeCode}

\vspace{\baselineskip}
Since memory is being assigned dynamically, it also has to be freed dynamically. To help with this, a help function is used. This helper function is given a node that does a depth-first search, and frees nodes as it searches, working its way bottom up. This is used to free memory as needed throughout, and all memory at the end. Refer to appendix \ref{fig:freeNodes}


\begin{figure}[H]
    \begin{lstlisting}[
        language=C,
        numbers=left,
        stepnumber=1,
        numbersep=5pt,
        xleftmargin=1.5em,
        frame=none
    ]
    // Buffer to store the current example read.
    char *current_line = NULL; // 
    size_t line_buffer_len = 0;
    ssize_t read_line_len = 0;
    
    //Read line by line until the end of the file has been reached.
    while((read_line_len = getline(&current_line, &line_buffer_len, file_ptr)) != -1){

        current_line[read_line_len - 1] = '\0';

        //building the naive parse tree for each string
        // So the root node for each parse tree
        Node *current_tree = build_basic_node(); // appendix 6.1
        current_tree->capacity = 10; // randomly assigned
        current_tree->t_label = 0;
        current_tree->children = calloc(current_tree->capacity, sizeof(Node*));

        // Going through all the characters in the string 1 by 1. 
        // Building the terminal nodes, assign a character value to the node.
        for(int i = 0; i < (read_line_len - 1); i ++ ){
            Node * node = build_basic_node();
            node->parent = current_tree;
            node->character = current_line[i];
            node->pos = i;
            current_tree->children[current_tree->num_child] = node;
            current_tree->num_child ++;
            // checking current trees' capacity
            // increase appropriately if needed
            check_node_capacity(current_tree);

        }

        // Check current capacity of the root node.
        // Increase appropriately
        root_trees->rootNodes[root_trees->count] = current_tree;
        root_trees->count = root_trees->count + 1;
        check_nodes_capacity(root_trees);

    }
    
    // Free buffer
    free(current_line);

\end{lstlisting}

\caption{Building each initial parse tree}
\label{fig:buildeachParseTree}
\end{figure}

\subsection{Pre-tokenisation}


\begin{figure}[H]
    \begin{lstlisting}[
        language=C,
        numbers=left,
        stepnumber=1,
        numbersep=5pt,
        xleftmargin=1.5em,
        frame=none
    ]
     // Step 2: Toggeling pre-tokenisation
     // Section III-E of Original paper
     int tokenise = 0;

     if(tokenise){
        for (int i = 0; i < root_trees->count; i ++){
            pre_tokenise(root_trees->rootNodes[i]);
        }
     }



    \end{lstlisting}

\caption{Pre-tokenisaiton of each root node}
\label{fig:pre-tokenise in main loop}
\end{figure}
    
After the inital parse trees , pre-tokenisation, from section III-A of the original paper \cite{kulkarniLearningHighlyRecursive2021} was implemented. This involved looping through each parse tree in the $Nodes$ structure, and for each prase tree, looping through all the leaf nodes, grouping all consective sequence of leaf nodes of the same class and putting them under a intermediate node sitting between the root node and a sequence of nodes, also known as a label node. Pre-tokenisation of each parse tree was encapsulated inside a function, which performed the pre-tokenisation given the root $t_0$ of a prase tree. 

\vspace{\baselineskip}
Given a root $t_0$, the function first detaches all the children ($c_0, c_1, ... c_n$) form the root $t_0$. This is just done by assigning an empry list to the root's childern list pointer, and storing the list of children $c_0, c_1, ... c_n$ into a new variable. It then builds an empty new node, the intermediate non-terminal label node $t_i$, and starts iterating over the childern $c_0, c_1, ... c_n$. It takes the frist child node $c_0$, assign it as a child of $t_i$ keeping track of the class and the number of nodes assigned to $t_i$ (lenght of sequence of same class). Then it will go through $c_1, c_2 ... c_n$, and as long as the current child $c_i$ is of the same class it will continue assign it as a child of $t_i$. When a punction or a $c_i$ of a different class is found, if $t_i$ houses a sequence of children greater than 1, it will then assign $t_i$ as a child of root $t_0$ and a new non-terminal node $t_j$ is built. After, same process is repeated. If $t_i$ ever houses a sequence of lenght 1 when class changes, and the sequence of different class begin, $t_i$ is dissolved, and child $c_p$, is directly linked with the root $t_0$, and it is freshly restarted with a new non-terminal label node $t_k$, same is done for punction. Essentially, only having an intermediate non-terminal label nodes for leaf nodes in the same class and that form a consective sequence of length 2 or greater.
Refer to appendix \ref{fig:Pre_tokeniser} and \ref{fig:pre_tokenise helper}.

\subsection{MergeAllValid}

Next implementation is 