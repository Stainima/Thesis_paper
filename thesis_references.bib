@online{aliPragmaticComparisonFour2021,
  title = {A {{Pragmatic Comparison}} of {{Four Different Programming Languages}}},
  author = {Ali, Saqib and Qayyum, Sammar},
  date = {2021-06-21},
  doi = {10.14293/S2199-1006.1.SOR-.PP5RV1O.v1},
  url = {https://scienceopen.com/hosted-document?doi=10.14293/S2199-1006.1.SOR-.PP5RV1O.v1},
  urldate = {2025-09-24},
  abstract = {Programming language debates are extremely common among programmers, computer science students and of course, software engineers. However, all of the abovementioned professionals can concur that different languages excel in different scenarios. Software Engineers and programmers working on different projects can easily use different languages for different tasks during their work. Every year different programming languages are designed and created. In this Research, we will keep in focus the Four Horsemen of programming languages: C, C++, Python and Java; with respect to the criteria of time, speed and simplicity. The same optimized piece of pseudo-code is used to write the code of the different programming languages mentioned above by following their respective syntax and rules. The results of the comparison will be displayed with the help of a table in order to simplify the final results for the reader.},
  langid = {english},
  pubstate = {prepublished}
}

@article{bastaniSynthesizingProgramInput,
  title = {Synthesizing {{Program Input Grammars}}},
  author = {Bastani, Osbert and Sharma, Rahul and Aiken, Alex and Liang, Percy},
  abstract = {We present an algorithm for synthesizing a context-free grammar encoding the language of valid program inputs from a set of input examples and blackbox access to the program. Our algorithm addresses shortcomings of existing grammar inference algorithms, which both severely overgeneralize and are prohibitively slow. Our implementation, GLADE, leverages the grammar synthesized by our algorithm to fuzz test programs with structured inputs. We show that GLADE substantially increases the incremental coverage on valid inputs compared to two baseline fuzzers.},
  langid = {english},
  file = {/Users/sulavmalla/Zotero/storage/2RG4RHY7/Bastani et al. - Synthesizing Program Input Grammars.pdf}
}

@inproceedings{bendrissouSynthesizingInputGrammars2022,
  title = {“{{Synthesizing}} Input Grammars”: A Replication Study},
  shorttitle = {“{{Synthesizing}} Input Grammars”},
  booktitle = {Proceedings of the 43rd {{ACM SIGPLAN International Conference}} on {{Programming Language Design}} and {{Implementation}}},
  author = {Bendrissou, Bachir and Gopinath, Rahul and Zeller, Andreas},
  date = {2022-06-09},
  pages = {260--268},
  publisher = {ACM},
  location = {San Diego CA USA},
  doi = {10.1145/3519939.3523716},
  url = {https://dl.acm.org/doi/10.1145/3519939.3523716},
  urldate = {2025-09-08},
  abstract = {When producing test inputs for a program, test generators (łfuzzersž) can greatly profit from grammars that formally describe the language of expected inputs. In recent years, researchers thus have studied means to recover input grammars from programs and their executions. The GLADE algorithm by Bastani et al., published at PLDI 2017, was the first blackbox approach to claim context-free approximation of input specification for non-trivial languages such as XML, Lisp, URLs, and more. Prompted by recent observations that the GLADE algorithm may show lower performance than reported in the original paper, we have reimplemented the GLADE algorithm from scratch. Our evaluation confirms that the effectiveness score (F1) reported in the GLADE paper is overly optimistic, and in some cases, based on the wrong language. Furthermore, GLADE fares poorly in several real-world languages evaluated, producing grammars that spend megabytes to enumerate inputs.},
  eventtitle = {{{PLDI}} '22: 43rd {{ACM SIGPLAN International Conference}} on {{Programming Language Design}} and {{Implementation}}},
  isbn = {978-1-4503-9265-5},
  langid = {english},
  file = {/Users/sulavmalla/Zotero/storage/8RXKN9GY/Bendrissou et al. - 2022 - “Synthesizing input grammars” a replication study.pdf}
}

@online{ChomskyHierarchyTheory2025,
  title = {Chomsky {{Hierarchy}} in {{Theory}} of {{Computation}}},
  date = {2025-07-23},
  url = {https://www.geeksforgeeks.org/theory-of-computation/chomsky-hierarchy-in-theory-of-computation/},
  urldate = {2025-10-08}
}

@thesis{chomskyTHREEMODELSTIE1956,
  type = {Papaer},
  title = {{{THREE MODELS FOR TIE DESCRIPTION OF LANGUAGE}}},
  author = {Chomsky, Noam},
  date = {1956},
  institution = {MIT},
  location = {Massachusetta},
  file = {/Users/sulavmalla/Zotero/storage/M2EC6BZ9/Chomsky - 1956 - THREE MODELS FOR TIE DESCRIPTION OF LANGUAGE.pdf}
}

@online{gopinathBuildingFastFuzzers2019,
  title = {Building {{Fast Fuzzers}}},
  author = {Gopinath, Rahul and Zeller, Andreas},
  date = {2019-11-18},
  eprint = {1911.07707},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1911.07707},
  url = {http://arxiv.org/abs/1911.07707},
  urldate = {2025-09-15},
  abstract = {Fuzzing is one of the key techniques for evaluating the robustness of programs against attacks. Fuzzing has to be effective in producing inputs that cover functionality and find vulnerabilities. But it also has to be efficient in producing such inputs quickly. Random fuzzers are very efficient, as they can quickly generate random inputs; but they are not very effective, as the large majority of inputs generated is syntactically invalid. Grammar-based fuzzers make use of a grammar (or another model for the input language) to produce syntactically correct inputs, and thus can quickly cover input space and associated functionality. Existing grammar-based fuzzers are surprisingly inefficient, though: Even the fastest grammar fuzzer dharma still produces inputs about a thousand times slower than the fastest random fuzzer. So far, one can have an effective or an efficient fuzzer, but not both. In this paper, we describe how to build fast grammar fuzzers from the ground up, treating the problem of fuzzing from a programming language implementation perspective. Starting with a Python textbook approach, we adopt and adapt optimization techniques from functional programming and virtual machine implementation techniques together with other novel domain-specific optimizations in a step-by-step fashion. In our F1 prototype fuzzer, these improve production speed by a factor of 100–300 over the fastest grammar fuzzer dharma. As F1 is even 5–8 times faster than a lexical random fuzzer, we can find bugs faster and test with much larger valid inputs than previously possible.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Programming Languages,Computer Science - Software Engineering},
  file = {/Users/sulavmalla/Zotero/storage/85VCLLFY/Gopinath and Zeller - 2019 - Building Fast Fuzzers.pdf}
}

@online{GrammarTheoryComputation2025,
  type = {Blog},
  title = {Grammar in {{Theory}} of {{Computation}}},
  date = {2025-08-25},
  url = {https://www.geeksforgeeks.org/theory-of-computation/introduction-to-grammar-in-theory-of-computation/},
  urldate = {2025-10-07},
  organization = {Grammar in Theory of Computation}
}

@thesis{hendriksConsiderItParsed,
  type = {Thesis},
  title = {Consider It {{Parsed}}!},
  author = {Hendriks, Max and Zaytsev, Vadim},
  institution = {University of Twente},
  location = {Enschede, Netherlands},
  abstract = {Relational parsing with context-free memoization, first presented in 2020, promises generalised contextfree parsing at speeds exceeding that of the current state-of-the-art parser generator: ANTLR4. Here, we present an independent attempt at bringing relational parsing to life based only on its original documentation, identify challenges when implementing it, and examine the capabilities of relational parsing. Our implementation of relational parsing can parse some challenging types of grammars, half of which ANTLR4 could not. However, there is a type of grammar that we cannot parse and for most tested grammars we did not manage to improve parsing speed by using context-free memoization. We expect these two caveats result from the way we implemented relational parsing rather than the method itself. We discuss some open questions that need answering before relational parsing can take its place as a practical and usable context-free parser.},
  langid = {english},
  file = {/Users/sulavmalla/Zotero/storage/JSV2PSMD/Hendriks and Zaytsev - Consider it Parsed!.pdf}
}

@article{jiangFormalGrammarsLanguages,
  title = {Formal {{Grammars}} and {{Languages}}},
  author = {Jiang, Tao and Li, Ming and Ravikumar, Bala and Regan, Kenneth W},
  langid = {english},
  file = {/Users/sulavmalla/Zotero/storage/2YJ2YF76/Jiang et al. - Formal Grammars and Languages.pdf}
}

@inproceedings{kulkarniLearningHighlyRecursive2021,
  title = {Learning {{Highly Recursive Input Grammars}}},
  booktitle = {2021 36th {{IEEE}}/{{ACM International Conference}} on {{Automated Software Engineering}} ({{ASE}})},
  author = {Kulkarni, Neil and Lemieux, Caroline and Sen, Koushik},
  date = {2021-11},
  pages = {456--467},
  publisher = {IEEE},
  location = {Melbourne, Australia},
  doi = {10.1109/ASE51524.2021.9678879},
  url = {https://ieeexplore.ieee.org/document/9678879/},
  urldate = {2025-09-08},
  abstract = {This paper presents ARVADA, an algorithm for learning context-free grammars from a set of positive examples and a Boolean-valued oracle. ARVADA learns a context-free grammar by building parse trees from the positive examples. Starting from initially flat trees, ARVADA builds structure to these trees with a key operation: it bubbles sequences of sibling nodes in the trees into a new node, adding a layer of indirection to the tree. Bubbling operations enable recursive generalization in the learned grammar. We evaluate ARVADA against GLADE and find it achieves on average increases of 4.98× in recall and 3.13× in F1 score, while incurring only a 1.27× slowdown and requiring only 0.87× as many calls to the oracle. ARVADA has a particularly marked improvement over GLADE on grammars with highly recursive structure, like those of programming languages.},
  eventtitle = {2021 36th {{IEEE}}/{{ACM International Conference}} on {{Automated Software Engineering}} ({{ASE}})},
  isbn = {978-1-6654-0337-5},
  langid = {english},
  file = {/Users/sulavmalla/Zotero/storage/Q9YPFLAN/Kulkarni et al. - 2021 - Learning Highly Recursive Input Grammars.pdf}
}

@article{kumarPythonLanguageComparison2022,
  title = {Python versus {{C Language}}: {{A Comparison}}},
  author = {Kumar, Rohit and Chander, Subhash and Chahal, Mandeep},
  date = {2022},
  volume = {9},
  abstract = {C and python has been proven programming language in their respective domain. Python has been a newer language in comparison to C language and offers rich set of libraries and offers significant support for newer application areas such as machine learning, whereas c has a proven and benchmark language for system programming and real time application development. Ease of coding in one perceptive that differentiate these programming languages. Other perspective is the application areas addressed by these programming languages. On this research paper all these parameters including efficiency, portability, application domains etc. has been discussed in details and comparison has been done for the same. Poularity comparison of both the langauges hgas also been done in w.r.t. each other ans w.r.t other majorly used programming languages.},
  langid = {english},
  file = {/Users/sulavmalla/Zotero/storage/C8X9UFNM/Kumar et al. - 2022 - Python versus C Language A Comparison.pdf}
}

@article{opensciencecollaborationEstimatingReproducibilityPsychological2015,
  title = {Estimating the Reproducibility of Psychological Science},
  author = {{Open Science Collaboration}},
  date = {2015-08-28},
  journaltitle = {Science},
  shortjournal = {Science},
  volume = {349},
  number = {6251},
  pages = {aac4716},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.aac4716},
  url = {https://www.science.org/doi/10.1126/science.aac4716},
  urldate = {2025-10-15},
  abstract = {Empirically analyzing empirical evidence                            One of the central goals in any scientific endeavor is to understand causality. Experiments that seek to demonstrate a cause/effect relation most often manipulate the postulated causal factor. Aarts               et al.               describe the replication of 100 experiments reported in papers published in 2008 in three high-ranking psychology journals. Assessing whether the replication and the original experiment yielded the same result according to several criteria, they find that about one-third to one-half of the original findings were also observed in the replication study.                                         Science               , this issue               10.1126/science.aac4716                        ,              A large-scale assessment suggests that experimental reproducibility in psychology leaves a lot to be desired.           ,                             INTRODUCTION               Reproducibility is a defining feature of science, but the extent to which it characterizes current research is unknown. Scientific claims should not gain credence because of the status or authority of their originator but by the replicability of their supporting evidence. Even research of exemplary quality may have irreproducible empirical findings because of random or systematic error.                                         RATIONALE               There is concern about the rate and predictors of reproducibility, but limited evidence. Potentially problematic practices include selective reporting, selective analysis, and insufficient specification of the conditions necessary or sufficient to obtain the results. Direct replication is the attempt to recreate the conditions believed sufficient for obtaining a previously observed finding and is the means of establishing reproducibility of a finding with new data. We conducted a large-scale, collaborative effort to obtain an initial estimate of the reproducibility of psychological science.                                         RESULTS                                We conducted replications of 100 experimental and correlational studies published in three psychology journals using high-powered designs and original materials when available. There is no single standard for evaluating replication success. Here, we evaluated reproducibility using significance and                 P                 values, effect sizes, subjective assessments of replication teams, and meta-analysis of effect sizes. The mean effect size (r) of the replication effects (                 M                 r                 = 0.197, SD = 0.257) was half the magnitude of the mean effect size of the original effects (                 M                 r                 = 0.403, SD = 0.188), representing a substantial decline. Ninety-seven percent of original studies had significant results (                 P                 {$<$} .05). Thirty-six percent of replications had significant results; 47\% of original effect sizes were in the 95\% confidence interval of the replication effect size; 39\% of effects were subjectively rated to have replicated the original result; and if no bias in original results is assumed, combining original and replication results left 68\% with statistically significant effects. Correlational tests suggest that replication success was better predicted by the strength of original evidence than by characteristics of the original and replication teams.                                                        CONCLUSION                                No single indicator sufficiently describes replication success, and the five indicators examined here are not the only ways to evaluate reproducibility. Nonetheless, collectively these results offer a clear conclusion: A large portion of replications produced weaker evidence for the original findings despite using materials provided by the original authors, review in advance for methodological fidelity, and high statistical power to detect the original effect sizes. Moreover, correlational evidence is consistent with the conclusion that variation in the strength of initial evidence (such as original                 P                 value) was more predictive of replication success than variation in the characteristics of the teams conducting the research (such as experience and expertise). The latter factors certainly can influence replication success, but they did not appear to do so here.                              Reproducibility is not well understood because the incentives for individual scientists prioritize novelty over replication. Innovation is the engine of discovery and is vital for a productive, effective scientific enterprise. However, innovative ideas become old news fast. Journal reviewers and editors may dismiss a new test of a published idea as unoriginal. The claim that “we already know this” belies the uncertainty of scientific evidence. Innovation points out paths that are possible; replication points out paths that are likely; progress relies on both. Replication can increase certainty when findings are reproduced and promote innovation when they are not. This project provides accumulating evidence for many findings in psychological research and suggests that there is still more work to do to verify whether we know what we think we know.                                                   Original study effect size versus replication effect size (correlation coefficients).                   Diagonal line represents replication effect size equal to original effect size. Dotted line represents replication effect size of 0. Points below the dotted line were effects in the opposite direction of the original. Density plots are separated by significant (blue) and nonsignificant (red) effects.                                                                         ,              Reproducibility is a defining feature of science, but the extent to which it characterizes current research is unknown. We conducted replications of 100 experimental and correlational studies published in three psychology journals using high-powered designs and original materials when available. Replication effects were half the magnitude of original effects, representing a substantial decline. Ninety-seven percent of original studies had statistically significant results. Thirty-six percent of replications had statistically significant results; 47\% of original effect sizes were in the 95\% confidence interval of the replication effect size; 39\% of effects were subjectively rated to have replicated the original result; and if no bias in original results is assumed, combining original and replication results left 68\% with statistically significant effects. Correlational tests suggest that replication success was better predicted by the strength of original evidence than by characteristics of the original and replication teams.},
  langid = {english},
  file = {/Users/sulavmalla/Zotero/storage/DI5GTHQY/Open Science Collaboration - 2015 - Estimating the reproducibility of psychological science.pdf}
}

@article{schroderStaticInferenceRegular,
  title = {Static {{Inference}} of {{Regular Grammars}} for {{Ad Hoc Parsers}}},
  author = {Schröder, Michael and Cito, Jürgen and family=Wien, given=TU, given-i=TU},
  langid = {english},
  file = {/Users/sulavmalla/Zotero/storage/QGDRZJGL/Schröder et al. - Static Inference of Regular Grammars for Ad Hoc Parsers.pdf}
}

@inproceedings{shepperdReplicationStudiesConsidered2018,
  title = {Replication Studies Considered Harmful},
  booktitle = {Proceedings of the 40th {{International Conference}} on {{Software Engineering}}: {{New Ideas}} and {{Emerging Results}}},
  author = {Shepperd, Martin},
  date = {2018-05-27},
  eprint = {1802.04580},
  eprinttype = {arXiv},
  eprintclass = {cs},
  pages = {73--76},
  doi = {10.1145/3183399.3183423},
  url = {http://arxiv.org/abs/1802.04580},
  urldate = {2025-10-09},
  abstract = {Objective: To consider what is required for a replication study to confirm the original experiment and apply this understanding in software engineering. Method: Simulation is used to demonstrate why the prediction interval for confirmation can be surprisingly wide. This analysis is applied to three recent replications. Results: It is shown that because the prediction intervals are wide, almost all replications are confirmatory, so in that sense there is no ‘replication crisis’, however, the contributions to knowledge are negligible. Conclusion: Replicating empirical software engineering experiments, particularly if they are under-powered or under-reported, is a waste of scientific resources. By contrast, meta-analysis is strongly advocated so that all relevant experiments are combined to estimate the population effect.},
  langid = {english},
  keywords = {Computer Science - Software Engineering},
  file = {/Users/sulavmalla/Zotero/storage/ZMXJGSI7/Shepperd - 2018 - Replication studies considered harmful.pdf}
}

@book{shiIntelligenceScience2021,
  title = {Intelligence {{Science}}},
  author = {Shi, Z},
  date = {2021},
  pagetotal = {215-266}
}
